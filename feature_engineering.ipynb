{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/lduque/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "CPU times: user 7min 29s, sys: 10.5 s, total: 7min 40s\n",
      "Wall time: 7min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from pipeline_utilities_insincere_questions import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from get_good_and_bad_words import get_good_and_bad_words\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "norm_model = gensim.models.KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "norm_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_inisincere.csv', index_col='qid')\n",
    "X_test = pd.read_csv('test_insincere.csv', index_col='qid')\n",
    "X = data[['question_text']]\n",
    "y = data.target\n",
    "X_train, X_dictionary, y_train, y_dictionary = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "data_dictionary =  pd.concat([X_dictionary, y_dictionary], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(261225, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dictionary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1044897, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56370, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "good_words, bad_words = get_good_and_bad_words(data_dictionary)\n",
    "bad_words = list(bad_words.sort_values(ascending=False).index)\n",
    "good_words = list(good_words.sort_values(ascending=False).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_sublists = 300\n",
    "chunk_bad_words = [bad_words[x:x+size_sublists] for x in xrange(0, len(bad_words), size_sublists)]\n",
    "chunk_good_words = [good_words[x:x+size_sublists] for x in xrange(0, len(good_words), size_sublists)]\n",
    "worst_sentence = ' '.join(chunk_bad_words[0])\n",
    "best_sentence = ' '.join(chunk_good_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "muslims liberals trump white women castrated indians men americans democrats christians hillary people jews whites shithole blacks hindus black muslim racist obama brainwashed castrate feminists atheists girls gay realize castrating fuck hate bhakts stupid conservatives enslaved leftists asians republicans supporters shabbat clinton rape liberal gujaratis sex muhajirs donald xenophobic pakistanis fucking modi gays incest indian clintons palestinians islam chinese raping rapists superior mullahs hypocrites quora crimes israel raped shit racists homosexuals brahmins president democrat assholes american jewish dumb ignorant filth america kill holocaust racism asian homosexual islamization ass hindu dick idiots terrorists zealanders israelis homosexuality males deny europeans husbands lynched believe tamilians minorities guys wives illegals violent illiterate islamist tamils dont sister troll ugly kannadigas guns boys zionism fucked bullshit pakistani transgender losers easterners stereotyped morons arabs sikhs dalits immigrants jew christian obsessed africans islamic congress fact british genocide destroying russians democratic majority blame killing terrorist hypocritical germans african nazis true seem think rapes mueller crap god bjp voters party many pussy us outrage cousin claim feminist race reparations palestinian children destroy man filipinos turks woman mccabe murdering sexual sjws hitler religious rights castration serbs religion progressives terrorism fyrom damn slaves atheism mom isis deserve cowards murderers bunch depraved extermination evolutionists vote killed bestiality lies slavs sonia respect bitch rushed bosnians goon judaic sexist filipina kaaba marry barack north rapist privilege biased bosniaks ashamed pelosi asshole skinned since voted isnt realise suck fake murdered rohingya penis races pedophilia russian zionist hatred south testicle malays vegans inferior moderators arrogant whiter idiotic lesbians sexually western hypocrisy slave streets pakistan equality poor proud country illegal everyone daughter lol election westernized sotu horrors iranians victimized unappealing smriti incels inuit innocent normalizing agree murder semitic bengalis benghazi jealous sanders sheeple questions racial refugees steal moderation westerners feminism whores debunked liars unborn calling victims finally millions\n"
     ]
    }
   ],
   "source": [
    "print worst_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best good get life someone engineering difference use business job online college book company work used books exam computer possible study different student career university learn process rank experience prepare app ways design one software admission find marks data degree learning important tips write course way marketing buy water apply year website jee iit web mobile engineer required affect long cost major science start program technology would field examples management physics google card android system institute interview account movie number mean score phone improve time salary main writing available product month exams favorite function test youtube studying coaching programming invest download earn market top current energy colleges laptop causes meaning apps application happen bank pursue visa investment first types without school cse characteristics series preparation distance advice options international students class research air skills iphone role amazon machine car training using increase light type advantages price universities development travel service read network ms change weight new websites music recommend anxiety cbse industry scope project digital take speed model upsc letter code services electrical worth windows better medical factors startup economics board starting pune neet value visit food effective gate applications friend store chennai games happens minimum maths useful tv analysis companies getting instagram summer fast delhi depression vs two sales purpose describe video home space stock songs english overcome graduate check period differences temperature developer ex song facebook add phd future ssc money weather high offer mumbai hours pros method steps products person bitcoin art build original chemical interesting effects professional language could hyderabad accomplishments subject ever develop boyfriend electric contact famous entrance option solar quality impact file character terms days pressure apple thing things graduation benefits trading drive place choose bangalore finance uses paper play area studies branch email masters dubai body season dream customer working certificate known sector\n"
     ]
    }
   ],
   "source": [
    "print best_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "data=[]\n",
    "good_words=[]\n",
    "bad_words=[]\n",
    "X_dictionary =[]\n",
    "y_dictionary =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 19s, sys: 8.14 s, total: 12min 28s\n",
      "Wall time: 12min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "m = stringTransformer(colname='question_text', model=model)\n",
    "encoded_strings_train = m.transform(X_train)\n",
    "encoded_strings_test = m.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "m = stringComparison(col='question_text', sentence=worst_sentence, suffix='_worst', model=model, norm_model=norm_model)\n",
    "comparison_with_worst_sentence_train = m.transform(X_train)\n",
    "comparison_with_worst_sentence_test = m.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "m = stringComparison(col='question_text', sentence=best_sentence, suffix='_best',model=model, norm_model=norm_model)\n",
    "comparison_with_best_sentence_train = m.transform(X_train)\n",
    "comparison_with_best_sentence_test = m.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.concat([X_train.question_text, encoded_strings_train, comparison_with_worst_sentence_train, comparison_with_best_sentence_train], axis=1)\n",
    "test_features = pd.concat([X_test.question_text, encoded_strings_test, comparison_with_worst_sentence_test, comparison_with_best_sentence_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.to_csv(\"train_features.csv\")\n",
    "test_features.to_csv(\"test_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
