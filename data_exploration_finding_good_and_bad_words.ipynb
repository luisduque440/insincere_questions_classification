{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "We do a hypothesis testing to find 'good' and 'bad' words in the following way (Notice that we have around 80k insincere questions in a data set of 1.3M)\n",
    "* We make 100 samples ($df_1$, $df_2$, ...$df_{100}$), each containing 80k questions chosen at random.\n",
    "\n",
    "\n",
    "* For each word and for each of our samples we find the quotient  \n",
    "$$w_i =\\frac{\\text{number of times the word is in }df_i}{\\text{number of words in }df_i}$$\n",
    "\n",
    "\n",
    "* We make a sample dg with only insincere questions (roughly 80k questions) and for each word we find\n",
    "$$\\hat{w} =\\frac{\\text{number of times the word is in dg}}{\\text{number of words in dg}}$$\n",
    "\n",
    "\n",
    "* At this moment, for each `word` we have $W:=[w_1, w_2, w_3, ..., w_{100}]$ that roughly describes how likely is it that the word appears in a random question, and $\\hat{w}$ that describes how likely it is to find the word in an insincere question.\n",
    "\n",
    "\n",
    "* Notice that if it is the case that our `word` is a 'bad word' we expect it to be more common in the sample $dg$ than in the samples $df_i$, and hence we say that `word` is a `bad word` if $\\hat{w}> quintil_{95}(W)$. Similarly, we say that `word` is a `good word` if $\\hat{w} < quintil_{5}(W)$\n",
    "\n",
    "\n",
    "* At the end of this notebook we provide a data frame with `bad words` and another data frame with `good words` according to the previous definitions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from get_good_and_bad_words import get_good_and_bad_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_inisincere.csv', index_col='qid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p =data.target.value_counts().plot.bar(title='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_words, bad_words = get_good_and_bad_words(data[:100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(735,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2329,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "muslims        62.725718\n",
       "liberals       50.063252\n",
       "indians        46.419911\n",
       "blacks         44.518679\n",
       "gays           44.022740\n",
       "trump          43.851490\n",
       "women          41.710316\n",
       "tamils         39.257291\n",
       "ass            38.694949\n",
       "men            38.010088\n",
       "hindus         36.839726\n",
       "americans      35.862371\n",
       "white          33.306424\n",
       "democrats      30.213616\n",
       "muslim         30.031719\n",
       "people         30.010778\n",
       "jews           28.262370\n",
       "castration     28.199985\n",
       "gay            27.804152\n",
       "christians     27.512319\n",
       "whites         26.380525\n",
       "obama          25.999169\n",
       "europeans      25.145652\n",
       "castrated      24.791974\n",
       "asians         24.780436\n",
       "fuck           23.300383\n",
       "racist         23.228772\n",
       "hate           22.912011\n",
       "girls          22.649177\n",
       "black          22.033753\n",
       "                 ...    \n",
       "values          0.066777\n",
       "abraham         0.064749\n",
       "holy            0.064681\n",
       "fascism         0.061846\n",
       "celebrating     0.061734\n",
       "respected       0.061655\n",
       "executed        0.061628\n",
       "pushing         0.059191\n",
       "nowhere         0.057886\n",
       "awful           0.056348\n",
       "screw           0.056172\n",
       "snape           0.055835\n",
       "subjective      0.055616\n",
       "disgusting      0.055477\n",
       "veterans        0.054064\n",
       "suffering       0.052462\n",
       "breeds          0.051960\n",
       "dominate        0.050289\n",
       "means           0.048543\n",
       "globally        0.048465\n",
       "fails           0.048361\n",
       "puts            0.043620\n",
       "nobody          0.035744\n",
       "affair          0.029132\n",
       "france          0.020968\n",
       "surely          0.019400\n",
       "capita          0.011608\n",
       "military        0.010729\n",
       "temple          0.008711\n",
       "bags            0.001932\n",
       "Length: 2329, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_words.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "best            15.714790\n",
       "good             7.362767\n",
       "get              6.544825\n",
       "someone          5.522103\n",
       "difference       5.377975\n",
       "work             5.189375\n",
       "engineering      5.142801\n",
       "use              5.094091\n",
       "college          4.922048\n",
       "job              4.896898\n",
       "student          4.830560\n",
       "study            4.683208\n",
       "life             4.657521\n",
       "online           4.636310\n",
       "possible         4.574371\n",
       "learn            4.383128\n",
       "way              4.369264\n",
       "computer         4.225865\n",
       "university       4.058048\n",
       "company          3.992585\n",
       "business         3.925053\n",
       "app              3.858476\n",
       "phone            3.840721\n",
       "one              3.791584\n",
       "books            3.776788\n",
       "data             3.754845\n",
       "water            3.656811\n",
       "exam             3.623839\n",
       "book             3.621622\n",
       "find             3.592053\n",
       "                  ...    \n",
       "risk             0.093545\n",
       "getting          0.091541\n",
       "idea             0.090839\n",
       "regular          0.089020\n",
       "open             0.085547\n",
       "rules            0.080895\n",
       "channel          0.080344\n",
       "differ           0.079914\n",
       "conversation     0.078802\n",
       "individual       0.071871\n",
       "approach         0.069162\n",
       "background       0.066296\n",
       "topic            0.065795\n",
       "might            0.065268\n",
       "york             0.064960\n",
       "cut              0.064614\n",
       "easier           0.057011\n",
       "greatest         0.054072\n",
       "advanced         0.053328\n",
       "personality      0.052344\n",
       "resources        0.050672\n",
       "shows            0.046438\n",
       "fix              0.037964\n",
       "universe         0.031572\n",
       "star             0.025336\n",
       "drive            0.023541\n",
       "videos           0.022806\n",
       "master           0.019415\n",
       "self             0.009744\n",
       "visit            0.008380\n",
       "Length: 735, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_words.sort_values(ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
